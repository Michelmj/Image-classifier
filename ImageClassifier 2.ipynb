{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--dirdata', help = 'directory for data')\n",
    "parser.add_argument('--dirsave', help = 'saving the data')\n",
    "parser.add_argument('--epochs', default = 5, help = 'number of epochs')\n",
    "parser.add_argument('--arch', default = 'alexnet')\n",
    "parser.add_argument('--rate', default = 0.001, help = 'learning rate')\n",
    "parser.add_argument('--gpu', dest = 'gpu', help = 'using gpu')\n",
    "parser.add_argument('--hidden', dest = 'hidden', help = 'hidden layer')\n",
    "\n",
    "args = parser.parse_args()\n",
    "epochs = args.epochs\n",
    "arch = args.arch\n",
    "rate = args.rate\n",
    "hidden = args.hidden\n",
    "gpu = args.gpu\n",
    "\n",
    "dirdata = './flowers'\n",
    "training_dir = dirdata + '/train'\n",
    "val_dir = dirdata + '/valid'\n",
    "testing_dir = dirdata + '/test'\n",
    "\n",
    "# Defining transforms for training, validation, and testing\n",
    "\n",
    "training_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([.485, .456, .406],\n",
    "                         [.229, .224, .225])])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([.485, .456, .406],\n",
    "                         [.229, .224, .225])])\n",
    "\n",
    "testing_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([.485, .456, .406],\n",
    "                         [.229, .224, .225])])\n",
    "\n",
    "# Load the dataset with ImageFolder\n",
    "training_data = datasets.ImageFolder(training_dir, transform = training_transforms)\n",
    "val_data = datasets.ImageFolder(val_dir, transform = val_transforms)\n",
    "testing_data = datasets.ImageFolder(testing_dir, transform = testing_transforms)\n",
    "\n",
    "# Using the image datasets and the transforms, define the dataloaders\n",
    "trainingloader = torch.utils.data.DataLoader(training_data, batch_size = 64, shuffle = True)\n",
    "valoader = torch.utils.data.DataLoader(val_data, batch_size = 64, shuffle = True)\n",
    "testingloader = torch.utils.data.DataLoader(testing_data, batch_size = 64, shuffle = True)\n",
    "\n",
    "imagesets = [training_data, val_data, testing_data]\n",
    "dataloaders = [trainingloader, valoader, testingloader]\n",
    "\n",
    "# Label mapping\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# Define device\n",
    "if args.gpu and torch.cuda.is_available == True:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "# We will use alexnet as the default from 'Part 1'\n",
    "if args.arch == 'alexnet':\n",
    "    model = models.alexnet(pretrained = True) \n",
    "elif arch == 'vgg16':\n",
    "    model = models.vgg16(pretrained = True) \n",
    "else:\n",
    "    model = models.densenet121(pretrained = True)\n",
    "\n",
    "\n",
    "# Build and train network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    OrderedDict([('fc1', nn.Linear(9216, 1024)),\n",
    "                 ('relu1', nn.ReLU()),\n",
    "                 ('drop1', nn.Dropout(p = 0.5)),\n",
    "                 ('fc2', nn.Linear(1024, 512)),\n",
    "                 ('relu2', nn.ReLU()),\n",
    "                 ('drop2', nn.Dropout(p = 0.5)),\n",
    "                 ('fc3', nn.Linear(512, 102)),\n",
    "                 ('output', nn.LogSoftmax(dim = 1))]))\n",
    "model.classifier = classifier\n",
    "\n",
    "# Initialization of criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr = args.rate)\n",
    "model.to(device)\n",
    "\n",
    "# Track the loss and accuracy on the validation set\n",
    "def validation(model, valoader, criterion):\n",
    "    model.to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for ii, (images, labels) in valoader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logps = model.forward(images)\n",
    "        loss += criterion(logps, labels).item()\n",
    "        \n",
    "        ps = torch.exp(logps)\n",
    "        equals = (labels.data == ps.max(dim = 1)[1])\n",
    "        accuracy += equals.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return loss, accuracy\n",
    "\n",
    "print_every = 28\n",
    "steps = 0\n",
    "\n",
    "# Running through epochs\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for ii, (images, labels) in enumerate(trainingloader):\n",
    "        steps += 1\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                loss, accuracy = validation(model, valoader, criterion)\n",
    "                \n",
    "            print('Epoch {}/{}..'.format(epoch + 1, epochs),\n",
    "                  'Training Loss: {:.3f}..'.format(running_loss / print_every),\n",
    "                  'Valid Loss: {:.3f}..'.format(loss/len(valoader)),\n",
    "                  'Valid Accuracy: {:.3f}%'.format(accuracy/len(valoader) * 100))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "# Checkpoint\n",
    "model.to('cpu')\n",
    "model.class_to_idx = training_data.class_to_idx\n",
    "\n",
    "checkpoint = {'epochs': epochs,\n",
    "              'mapping': model.class_to_idx,\n",
    "              'arch': arch,\n",
    "              'classifier': model.classifier,\n",
    "              'state_dict': model.state_dict(),\n",
    "              }\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import os, random\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('image_path', action = 'store')\n",
    "parser.add_argument('checkpoint', action = 'store')\n",
    "parser.add_argument('--topkm', default = 3, type = int)\n",
    "parser.add_argument('--name_category', action = 'store')\n",
    "parser.add_argument('--gpu', dest = 'gpu')\n",
    "\n",
    "args = parser.parse_args()\n",
    "image_path = args.image_path\n",
    "checkpoint = args.checkpoint\n",
    "\n",
    "# Write a function that loads a checkpoint and rebuilds the model\n",
    "def modeload(checkpoint = 'checkpoint.pth'):\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    \n",
    "    arch = checkpoint['arch']\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.epochs = checkpoint['epochs']\n",
    "    model.class_to_idx = checkpoint['mapping']\n",
    "        \n",
    "    return model\n",
    "\n",
    "# Image Preprocessing\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array'''\n",
    "    imaj = Image.open(image)\n",
    "    bonimaj = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [.485, .456, .406],\n",
    "                             std = [.229, .224, .225])])\n",
    "    \n",
    "    imajforms = bonimaj(imaj)\n",
    "    return imajforms\n",
    "    \n",
    "# Implement the code to predict the class from an image file\n",
    "def predict(path, model, topkm):\n",
    "    if gpu and torch.cuda.is_available() == 'gpu':\n",
    "        model.to('cuda:0')\n",
    "    \n",
    "    # The image        \n",
    "    image = process_image(path)\n",
    "    image = image.unsqueeze_(0).float()\n",
    "    if gpu == 'gpu':\n",
    "        with torch.no_grad():\n",
    "            image = image.cuda()\n",
    "            output = model.forward(image)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            output = model.forward(image)\n",
    "            \n",
    "    probability = F.softmax(output.data, dim = 1)\n",
    "    \n",
    "    return probability.topk(topkm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
